{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfae1cf9",
   "metadata": {},
   "source": [
    "# Cat vs Dog Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2176333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:08.944736Z",
     "start_time": "2023-04-16T18:21:08.919680Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install bing-image-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c62fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:16.207730Z",
     "start_time": "2023-04-16T18:21:08.947103Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bing_image_downloader import downloader\n",
    "from pathlib import Path\n",
    "import imghdr\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from hydrop_sharepointsync.sync import import_from_sharepoint, export_to_sharepoint\n",
    "\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64896757",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a2746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:16.218116Z",
     "start_time": "2023-04-16T18:21:16.214226Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"./data/cat_dogs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38187af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:16.223190Z",
     "start_time": "2023-04-16T18:21:16.220293Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_images(query, limit, output_dir):\n",
    "    \n",
    "    downloader.download(query,\n",
    "                        limit=limit,\n",
    "                        output_dir=output_dir,\n",
    "                        adult_filter_off=True,\n",
    "                        force_replace=False,\n",
    "                        timeout=60)\n",
    "\n",
    "download_images(\"cat\", 100, image_path)\n",
    "download_images(\"dog\", 100, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702eea50",
   "metadata": {},
   "source": [
    "### Check the downloaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3ae4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:16.324642Z",
     "start_time": "2023-04-16T18:21:16.226562Z"
    }
   },
   "outputs": [],
   "source": [
    "for category in [\"cat\",\"dog\"]:\n",
    "    data_dir = os.path.join(image_path, category)\n",
    "    image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "    img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "    for filepath in Path(data_dir).rglob(\"*\"):\n",
    "        if filepath.suffix.lower() in image_extensions:\n",
    "            img_type = imghdr.what(filepath)\n",
    "            if img_type is None:\n",
    "                print(f\"{filepath} is not an image\")\n",
    "            elif img_type not in img_type_accepted_by_tf:\n",
    "                print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f98888",
   "metadata": {},
   "source": [
    "**Delete any invalid images**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800070f",
   "metadata": {},
   "source": [
    "## Set up the sharepoint sync path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get paths from environment variables\n",
    "sharepoint_source_path = os.getenv('SHAREPOINT_SOURCE_PATH')\n",
    "local_destination_path = os.getenv('LOCAL_DESTINATION_PATH')\n",
    "local_source_path = os.getenv('LOCAL_SOURCE_PATH')\n",
    "sharepoint_destination_path = os.getenv('SHAREPOINT_DESTINATION_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f098b9",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f592e",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3e894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:16.329619Z",
     "start_time": "2023-04-16T18:21:16.326607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters and input data\n",
    "learning_rate = 0.02\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "input_shape = (224, 224, 3)\n",
    "expno = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a95a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:16.334372Z",
     "start_time": "2023-04-16T18:21:16.331598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define names for tensorboard logging and mlflow\n",
    "experiment_name = \"cat-dog-classifier\"\n",
    "run_name = f\"Experiment_{expno}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1927480",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebc68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:43.033152Z",
     "start_time": "2023-04-16T18:21:42.937468Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    image_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12367cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:44.201027Z",
     "start_time": "2023-04-16T18:21:44.156984Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    image_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e902e",
   "metadata": {},
   "source": [
    "Look at some sample images from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f2151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:47.804556Z",
     "start_time": "2023-04-16T18:21:45.348603Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d79c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:49.271286Z",
     "start_time": "2023-04-16T18:21:47.807010Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in val_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804fe92",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b59bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:49.283301Z",
     "start_time": "2023-04-16T18:21:49.273219Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709e8e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:21:59.377596Z",
     "start_time": "2023-04-16T18:21:56.507351Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images, training=True)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04682a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:22:01.044177Z",
     "start_time": "2023-04-16T18:22:00.940068Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_train_dataset = train_dataset.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbe7be",
   "metadata": {},
   "source": [
    "### Define Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd3f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:22:03.022088Z",
     "start_time": "2023-04-16T18:22:02.126635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the base model and add a classifier on top\n",
    "base_model = MobileNet(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "base_model.trainable = False\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc1a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:22:04.061527Z",
     "start_time": "2023-04-16T18:22:04.044892Z"
    }
   },
   "outputs": [],
   "source": [
    " # Compile the model with a loss function and optimizer\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3a2d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:22:04.554655Z",
     "start_time": "2023-04-16T18:22:04.550976Z"
    }
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", experiment_name, run_name)\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=logdir, write_graph=True, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49594d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:28:34.425526Z",
     "start_time": "2023-04-16T18:22:06.557025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model and log metrics and the model itself to MLflow\n",
    "history = model.fit(\n",
    "    augmented_train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_dataset,\n",
    "    verbose=2,\n",
    "    callbacks=[tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df26167",
   "metadata": {},
   "source": [
    "## MLFLow Logging and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a6439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:28:58.745845Z",
     "start_time": "2023-04-16T18:28:34.428012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the experiment name and create an MLflow run\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(run_name = run_name) as mlflow_run:\n",
    "    \n",
    "    mlflow.set_experiment_tag(\"base_model\", \"MobileNet\")\n",
    "    mlflow.set_tag(\"dataset\", \"cat_dog\")\n",
    "    mlflow.set_tag(\"optimizer\", \"keras.optimizers.Adam\")\n",
    "    mlflow.set_tag(\"loss\", \"sparse_categorical_crossentropy\")\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"input_shape\", input_shape)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", history.history[\"loss\"][-1])\n",
    "    mlflow.log_metric(\"train_acc\", history.history[\"accuracy\"][-1])\n",
    "    mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][-1])\n",
    "    mlflow.log_metric(\"val_acc\", history.history[\"val_accuracy\"][-1])\n",
    "\n",
    "    # Log an artifact (e.g., a plot)\n",
    "    import matplotlib.pyplot as plt\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    x_axis = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.suptitle('Training Statistics', fontsize='xx-large')\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    ax1.set_title('Loss')\n",
    "    # ax1.set_yscale('log') \n",
    "    ax1.plot(x_axis, loss)\n",
    "    ax1.plot(x_axis, val_loss)\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "    ax2.set_title('Accuracy')\n",
    "    # ax2.set_yscale('log') \n",
    "    ax2.plot(x_axis, acc)\n",
    "    ax2.plot(x_axis, val_acc)\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    plt.savefig(\"plot.png\")\n",
    "    mlflow.log_artifact(\"plot.png\")\n",
    "\n",
    "    mlflow_run_id = mlflow_run.info.run_id\n",
    "    print(\"MLFlow Run ID: \", mlflow_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6d316",
   "metadata": {},
   "source": [
    "### Export MLFLow Artifacts to Sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to SharePoint\n",
    "export_to_sharepoint(local_source_path, sharepoint_destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4df87",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8a92a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:28:58.783597Z",
     "start_time": "2023-04-16T18:28:58.771051Z"
    }
   },
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    os.path.join(image_path, \"cat/Image_17.jpg\"), target_size=input_shape\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1638b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T18:28:59.697822Z",
     "start_time": "2023-04-16T18:28:58.786481Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(img_array)\n",
    "print(\"This image is {:.2f}% cat and {:.2f}% dog.\".format(100 * float(predictions[0][0]),\n",
    "                                                          100 * float(predictions[0][1])))\n",
    "\n",
    "plt.imshow(img_array[0].numpy().astype(\"uint8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
